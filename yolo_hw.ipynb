{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKdcvMtSMpSg"
      },
      "source": [
        "#Майнор ИАД. Домашнее задание 3. YOLO.\n",
        "\n",
        "В этом задании вы напишете и обучите свой собственный YOLO детектор. Нужно будет разобраться со статьей: понять какого формата должна быть обучающая пара (x, y), как перевести лосс из математической формулы в питоновский код - ну и конечно понять и реализовать саму архитектуру модели.\n",
        "\n",
        "Выборка на котрой мы будем обучать модель состоит из разнообразных фотографий яблок, бананов и апельсинов. Данные скачиваем [отсюда](https://drive.google.com/file/d/1d8GSfZoWbraWCSUhX78yl4CnMFYE-5n3/view?usp=sharing).\n",
        "\n",
        "Баллы за ДЗ распределены следующим образом: \n",
        "- Выборка для YoloV1 - 2 балла\n",
        "- YOLO модель - 2 балла\n",
        "- YOLO Loss - 3 балла\n",
        "- Вспомогательные функции - 2 балла\n",
        "- Обучение и расчет метрик - 2 балла\n",
        "\n",
        "Для построения и обучения можно использовать как pytorch, так и pytorch-lightning.\n",
        "\n",
        "Да-да, баллов в сумме получается 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY4niK1xMpSg"
      },
      "outputs": [],
      "source": [
        "# Данная библиотека понадобится нам, чтобы обработать разметку\n",
        "! pip install xmltodict pytorch-lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNSQ7FNss30F"
      },
      "source": [
        "Скачаем данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN1dE6eY7PjV"
      },
      "outputs": [],
      "source": [
        "!wget --quiet --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://drive.google.com/uc?export=download&id=1d8GSfZoWbraWCSUhX78yl4CnMFYE-5n3' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1d8GSfZoWbraWCSUhX78yl4CnMFYE-5n3\" -O data.zip && rm -rf /tmp/cookies.txt\n",
        "!unzip -q data.zip\n",
        "!rm data.zip\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep38vdW_s-Rz"
      },
      "source": [
        "Посмотрим как выглядит один из файлов разметки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqwaHl3ntBaN"
      },
      "outputs": [],
      "source": [
        "!cat data/train/apple_3.xml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdQxrA5_MpSg"
      },
      "source": [
        "## Релизуйте выборку для YoloV1 - 2 балла"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXG9reop-BkS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import glob\n",
        "import tqdm\n",
        "import xmltodict\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torchvision\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import albumentations as A\n",
        "import albumentations.pytorch\n",
        "\n",
        "from IPython.core.display import struct\n",
        "from typing import List\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gL8_CyyTYJ-"
      },
      "source": [
        "Так как в этом домашнем задании использовать аугментации для обучения __обязательно__ - советуем воспользоваться библиотекой albumentations.\n",
        "\n",
        "Она  особенно удобна, поскольку умеет сама вычислять новые координаты bounding box'ов после трансформаций картинки. Для знакомства с этим механизмом советуем следующий [гайд](https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/). \n",
        "\n",
        "Вы все еще можете избрать путь torchvision.transforms, вам потребуется знакомый нам метод `__getitem__`, однако вычислять новые координаты bounding box'ов после трансформаций вам придётся вручную\n",
        "\n",
        "__Обратите внимание__ на то, что в статье коробки предсказаний параметризуются через: _(x_center, y_center, width, height)_ (причем эти значения _относительные_), а в наших файлах - это _(x_min, y_min, x_max, y_max)_\n",
        "\n",
        "Также, помните что модель должна предсказывать как прямоугольник с обьектом, так и вероятности каждого класса!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def comparison(data_dir):\n",
        "    path = os.path.join(os.getcwd(), data_dir)\n",
        "    answer = {}\n",
        "    count = 0\n",
        "    for filename in os.listdir(path):\n",
        "        name = filename.split('.')[0]\n",
        "        if name not in answer.keys():\n",
        "            answer[name] = count\n",
        "            count += 1\n",
        "    return answer\n",
        "\n",
        "def paths(labels, data_dir):\n",
        "    path = os.path.join(os.getcwd(), data_dir)\n",
        "    path_im = {}\n",
        "    path_box = {}\n",
        "    for name in list(labels.keys()):\n",
        "        num = labels[name]\n",
        "        path_im[num] = os.path.join(path, (name + '.jpg'))\n",
        "        path_box[num] = os.path.join(path, (name + '.xml'))\n",
        "    return path_im, path_box"
      ],
      "metadata": {
        "id": "RMOpcgjmPAV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjZkU0vzMpSh"
      },
      "outputs": [],
      "source": [
        "class2tag = {\"apple\": 1, \"orange\": 2, \"banana\": 3}\n",
        "\n",
        "class FruitDataset(Dataset):\n",
        "    def __init__(self, data_dir, transforms=None):\n",
        "        self.biection = comparison(data_dir)\n",
        "        self.image_paths, self.box_paths = paths(self.biection, data_dir)\n",
        "        assert len(self.image_paths) == len(self.box_paths)\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.array(Image.open(self.image_paths[idx]).convert(\"RGB\"))\n",
        "        bboxes, labels = self.__get_boxes_from_xml(self.box_paths[idx])\n",
        "        bboxes = (self.__convert_to_yolo_box_params(bboxes, image.shape[1], image.shape[0]))\n",
        "        if self.transforms:\n",
        "            transformed = self.transforms(image = image, bboxes = bboxes, labels = labels)\n",
        "            bboxes = transformed['bboxes']\n",
        "            image = transformed['image']\n",
        "            labels = transformed['labels']\n",
        "\n",
        "        return torch.Tensor(image).permute(2, 0, 1), (bboxes, labels)\n",
        "\n",
        "        return image, target_tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __get_boxes_from_xml(self, xml_filename: str):\n",
        "        boxes = []\n",
        "        class_labels = []\n",
        "\n",
        "        for object in ET.parse(xml_filename).getroot().iter('object'):\n",
        "            name = object.find('name').text\n",
        "            xmin = int(object.find('bndbox').find('xmin').text)\n",
        "            ymin = int(object.find('bndbox').find('ymin').text)\n",
        "            xmax = int(object.find('bndbox').find('xmax').text)\n",
        "            ymax = int(object.find('bndbox').find('ymax').text)\n",
        "\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            class_labels.append(class2tag[name])\n",
        "\n",
        "        return boxes, class_labels\n",
        "\n",
        "    def __convert_to_yolo_box_params(self, box_coordinates: List[int], im_w, im_h):\n",
        "        answers = []\n",
        "        for box_coordinate in box_coordinates:\n",
        "            ans = []\n",
        "            ans.append((box_coordinate[0] + box_coordinate[2]) / 2 / im_w)\n",
        "            ans.append((box_coordinate[1] + box_coordinate[3]) / 2 / im_h)\n",
        "\n",
        "            ans.append((box_coordinate[2] - box_coordinate[0]) / im_w)\n",
        "            ans.append((box_coordinate[3] - box_coordinate[1]) / im_h)\n",
        "            answers.append(ans)\n",
        "\n",
        "        return answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwXeSiAjdGeq"
      },
      "outputs": [],
      "source": [
        "WIDTH, HEIGHT = 448, 448\n",
        "\n",
        "train_transform = A.Compose([albumentations.augmentations.geometric.resize.Resize(height=HEIGHT, width = WIDTH),\n",
        "    A.HorizontalFlip(p=0.3), A.Transpose(p=0.3), A.PixelDropout(p=0.5), A.RandomRotate90(p=0.3),\n",
        "    A.Blur(blur_limit=(3,4), p=0.5)], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "test_transform = A.Compose([albumentations.augmentations.geometric.resize.Resize(height=HEIGHT, width = WIDTH)],\n",
        "                           bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayPwbRKocdCE",
        "outputId": "5c38b99f-1907-41e9-de05-56d50be9ea4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тесты успешно пройдены\n"
          ]
        }
      ],
      "source": [
        "train_dataset = FruitDataset(\n",
        "    transforms=train_transform,\n",
        "    data_dir=\"./data/train\"\n",
        "    )\n",
        "\n",
        "val_dataset = FruitDataset(\n",
        "    transforms=test_transform, \n",
        "    data_dir=\"./data/test\"\n",
        "    )\n",
        "\n",
        "# Немного проверок, чтобы убедиться в правильности направления решения\n",
        "assert isinstance(train_dataset[0], tuple)\n",
        "assert len(train_dataset[0]) == 2\n",
        "assert isinstance(train_dataset[0][0], torch.Tensor)\n",
        "print(\"Тесты успешно пройдены\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V1Tl_GAdeIv"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size= 4,\n",
        "    shuffle=True)\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=4, \n",
        "    shuffle=False\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fRR9ns6MpSh"
      },
      "source": [
        "Теперь определим функцию для рассчета Intersection Over Union по 4 углам двух прямоугольников"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rd88hnZiMpSh"
      },
      "outputs": [],
      "source": [
        "def intersection_over_union(predicted_bbox, gt_bbox) -> float:\n",
        "    \"\"\"\n",
        "    Intersection Over Union для двух прямоугольников\n",
        "\n",
        "    :param: predicted_bbox - [x_min, y_min, x_max, y_max]\n",
        "    :param: gt_bbox - [x_min, y_min, x_max, y_max]\n",
        "    \n",
        "    :return: Intersection Over Union\n",
        "    \"\"\"\n",
        "\n",
        "    intersection_bbox = np.array(\n",
        "        [\n",
        "            max(predicted_bbox[0], gt_bbox[0]),\n",
        "            max(predicted_bbox[1], gt_bbox[1]),\n",
        "            min(predicted_bbox[2], gt_bbox[2]),\n",
        "            min(predicted_bbox[3], gt_bbox[3]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    intersection_area = max(intersection_bbox[2] - intersection_bbox[0], 0) * max(\n",
        "        intersection_bbox[3] - intersection_bbox[1], 0\n",
        "    )\n",
        "    area_dt = (predicted_bbox[2] - predicted_bbox[0]) * (predicted_bbox[3] - predicted_bbox[1])\n",
        "    area_gt = (gt_bbox[2] - gt_bbox[0]) * (gt_bbox[3] - gt_bbox[1])\n",
        "\n",
        "    union_area = area_dt + area_gt - intersection_area\n",
        "\n",
        "    iou = intersection_area / union_area\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVJWo3xbMpSh"
      },
      "source": [
        "Теперь начинается основная часть домашнего задания: обучите модель YOLO для object detection на __обучающем__ датасете. \n",
        "\n",
        " - Создайте модель и функцию ошибки YoloV1 прочитав [оригинальную статью](https://paperswithcode.com/paper/you-only-look-once-unified-real-time-object)\n",
        " - Напишите функцию обучения модели\n",
        " - Используйте аугментации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxfMVwzHW2MJ"
      },
      "source": [
        "## Реализуйте Модель - 2 балла\n",
        "\n",
        "Копировать точное количество слоев и параметры сверток необязательно. Главное - чтобы модель работала по принципу, описанному в статье и делала предсказание в представленном формате.\n",
        "\n",
        "\n",
        "В качестве подсказки напомним, что выходом модели __для каждого обьекта__ должен быть тензор размера\n",
        "__S * S * (B * 5 + С)__, где все параметры имеют такое же значение, как и в статье: \n",
        "\n",
        "- S - количество ячеек на которое разбивается изображение по вертикали/горизонтали\n",
        "- В - количество предсказываемых прямоугольников в каждой ячейке\n",
        "- 5 - количество параметров для определения каждого прямоугольника (x_center, y_center, width, height, confidence)\n",
        "- С - количество классов (apple, banana, orange)\n",
        "\n",
        "Таким образом, мы для каждого окна размера __S x S__ предсказываем __В__ коробо и один класс"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PJwrvcWW1n7"
      },
      "outputs": [],
      "source": [
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self, convs, out_channels, is_max_pool:bool=False, **kwargs):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.conv_layers = convs\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
        "\n",
        "        self.is_maxpool = is_max_pool\n",
        "        self.maxpool = nn.MaxPool2d(2,stride=2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "\n",
        "        if len(x.size()) == 3:\n",
        "            x = x.unsqueeze(0)\n",
        "        x = self.leakyrelu(self.batchnorm(x))\n",
        "\n",
        "        if self.is_maxpool:\n",
        "            x = self.maxpool(x)\n",
        "        return x\n",
        "    \n",
        "class YOLO(nn.Module):\n",
        "    def __init__(self, S=7, B=2, C=3):\n",
        "        \n",
        "        super(YOLO, self).__init__()\n",
        "\n",
        "        self.S = S\n",
        "        self.B = B\n",
        "        self.C = C\n",
        "        self.conv_block_1 = CNNBlock(nn.Sequential(nn.Conv2d(\n",
        "            in_channels=3, out_channels=192, kernel_size=3, stride=2, padding=1)), 192, True)\n",
        "        \n",
        "        self.conv_block_2 = CNNBlock(nn.Sequential(nn.Conv2d(\n",
        "            in_channels=192, out_channels=256, kernel_size=3, padding=1)), 256, True)\n",
        "        \n",
        "        self.conv_block_3 = CNNBlock(nn.Sequential(nn.Conv2d(in_channels=256, out_channels=256, kernel_size=1),\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)), 512, True)\n",
        "        \n",
        "        self.conv_block_4 = CNNBlock(nn.Sequential(nn.Conv2d(\n",
        "            in_channels=512, out_channels=256, kernel_size=1),\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1),\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1),\n",
        "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1)), 1024, True)\n",
        "        \n",
        "        self.conv_block_5 = CNNBlock(nn.Sequential(nn.Conv2d(\n",
        "            in_channels=1024, out_channels=512, kernel_size=1),\n",
        "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=2, padding=1)), 1024, False)\n",
        "        \n",
        "        self.conv_block_6 = CNNBlock(nn.Sequential(nn.Conv2d(\n",
        "            in_channels=1024, out_channels=1024, kernel_size=3, padding=1)), 1024, False)\n",
        "        \n",
        "        self.linear_1 =  nn.Linear(7*7*1024, 4096)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
        "        self.linear_2 =  nn.Linear(4096, S*S*(B*5 + C))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block_1.forward(x)\n",
        "        x = self.conv_block_2.forward(x)\n",
        "        x = self.conv_block_3.forward(x)\n",
        "        x = self.conv_block_4.forward(x)\n",
        "        x = self.conv_block_5.forward(x)\n",
        "        x = self.conv_block_6.forward(x)\n",
        "        x = self.leaky_relu(self.linear_1(nn.Flatten()(x)))\n",
        "        x = self.linear_2(x).view(self.S,self.S,self.B*5 + self.C)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "testing_model = YOLO()\n",
        "expected_output_shape = testing_model.S * testing_model.S * (5 * testing_model.B + testing_model.C)\n",
        "\n",
        "testing_image = train_dataset[0][0]\n",
        "\n",
        "assert testing_model(testing_image).reshape(-1).shape[0] == expected_output_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJIjWKbcYUYe"
      },
      "source": [
        "## Реализуйте YoloLoss - 3 балла"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwJZ7o0BYTbB"
      },
      "outputs": [],
      "source": [
        "class YoloLoss(nn.Module):\n",
        "    def __init__(self, S=7, B=2, C=3):\n",
        "        \"\"\"\n",
        "        :param: S * S - количество ячеек на которые разбивается изображение\n",
        "        :param: B - количество предсказанных прямоугольников в каждой ячейке\n",
        "        :param: C - количество классов\n",
        "        \"\"\"\n",
        "        \n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
        "\n",
        "        self.S = S\n",
        "        self.B = B\n",
        "        self.C = C\n",
        "\n",
        "        self.lambda_noobj = 0.5\n",
        "        self.lambda_coord = 5\n",
        "\n",
        "    def forward(self, predictions, target):\n",
        "        predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B * 5)\n",
        "\n",
        "        iou_b1 = intersection_over_union(predictions[..., 21:25], target[..., 21:25])\n",
        "        iou_b2 = intersection_over_union(predictions[..., 26:30], target[..., 21:25])\n",
        "        ious = torch.cat([iou_b1.unsqueeze(0), iou_b2.unsqueeze(0)], dim=0)\n",
        "        iou_max, best_box = torch.max(ious, dim=0)\n",
        "        exists_box = target[..., 20].unsqueeze(3)\n",
        "\n",
        "        box_predictions = exists_box * (best_box * predictions[..., 26:30] + (1 - best_box) * predictions[..., 21:25])\n",
        "        box_targets = exists_box * target[..., 21:25]\n",
        "        box_predictions[..., 2:4] = torch.sign(box_predictions[..., 2:4]) * torch.sqrt(torch.abs(box_predictions[..., 2:4] + 1e-6))\n",
        "\n",
        "        box_targets[..., 2:4] = torch.sqrt(box_targets[..., 2:4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ1eev1EeNk7"
      },
      "source": [
        "## Реализуйте дополнительные функции из статьи - 2 балла"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMF8e6yXU6QV"
      },
      "outputs": [],
      "source": [
        "def non_max_suppression(bboxes, iou_threshold, threshold):\n",
        " \n",
        "\n",
        "def mean_average_precision(pred_boxes, true_boxes, iou_threshold=0.5):\n",
        "    ## YOUR CODE\n",
        "    pass\n",
        "\n",
        "def get_bound_boxes(loader, model, iou_threshold=.5, threshold=.4):\n",
        "    ## YOUR CODE\n",
        "    return all_pred_boxes, all_true_boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z38hYLM6haDk"
      },
      "source": [
        "## Обучите модель и посчитайте метрики для задачи детекции - 2 балла \n",
        "\n",
        "Несмотря на то, что в этом блоке ничего сильно нового для вас не ожидается и за него формально дается лишь два балла - провести обучение очень важно для понимания того, насколько правильно реализована ваша модель и лосс.\n",
        "\n",
        "В процессе обучения будет видно все ли размерности совпадают, падает ли лосс и растут ли метрики целевой задачи, поэтому на практике этот пункт гораздо оказывается гораздо важнее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BTNHNqtMpSi"
      },
      "outputs": [],
      "source": [
        "class YOLOLearner(pl.LightningModule):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = YOLO()\n",
        "        self.loss = YoloLoss()\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "\n",
        "    def forward(self, x) -> torch.Tensor:\n",
        "        return self.model(x)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return self.optimizer\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx) -> torch.Tensor:\n",
        "        ## YOUR CODE\n",
        "        pass\n",
        "\n",
        "    def validation_step(self, val_batch, batch_idx) -> None:\n",
        "        ## YOUR CODE\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRl42I2xMpSi"
      },
      "outputs": [],
      "source": [
        "model = # YOUR CODE\n",
        "n_epochs = # YOUR CODE\n",
        "\n",
        "yolo_learner = YOLOLearner(...)  ## YOUR CODE\n",
        "\n",
        "device = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
        "trainer = pl.Trainer(accelerator=device, max_epochs=n_epochs)\n",
        "\n",
        "trainer.fit(yolo_learner, train_dataloader, val_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb7ioohR96vu"
      },
      "source": [
        "## Посчитайте метрики задачи детекции на валидационной выборке\n",
        "\n",
        "Попробуйте понять насколько хороши ваши показатели. Если числа кажутся подозрительно низкими - возможно вам стоит перепроверить ваше решение. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUnlNeot98un"
      },
      "outputs": [],
      "source": [
        "## YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_YG71pYMpSi"
      },
      "source": [
        "## Визуализируйте предсказанные bounding box'ы для любых пяти картинок из __валидационного__ датасета."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgVdVzvMMpSi"
      },
      "outputs": [],
      "source": [
        "image, targets = next(iter(val_dataset))\n",
        "preds = ## YOUR CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpp4jHs0MpSi"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageDraw\n",
        "\n",
        "image = torchvision.transform.ToPILImage()(image)\n",
        "draw = ImageDraw.Draw(image)\n",
        "\n",
        "for box in targets[0]:\n",
        "    ## YOUR CODE\n",
        "    draw.rectangle([(box[0], box[1]), (box[2], box[3])])\n",
        "\n",
        "for box in preds[0]:\n",
        "    ## YOUR CODE\n",
        "    draw.rectangle([(box[0], box[1]), (box[2], box[3])], outline='red')\n",
        "image"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}